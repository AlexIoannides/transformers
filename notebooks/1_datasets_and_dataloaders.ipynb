{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets and Data Loaders\n",
    "\n",
    "In this notebook we show the data to be used for the language models that we'll be building later on. We will also give an overview of the tools that make working with data for the purposes of training deep learning models a lot easier."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "PyTorch's data utilities are located in `torch.utils.data` and we will also import some of our own tools from `modelling.data` (refer to the source code if you're interested in how they work)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from modelling.data import (\n",
    "    FilmReviewSequences,\n",
    "    GPTTokenizer,\n",
    "    IMDBTokenizer,\n",
    "    get_data,\n",
    "    make_sequence_datasets,\n",
    "    pad_seq2seq_data,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data\n",
    "\n",
    "The data that we will use are the set of movie reviews from IMDB that are hosted at: http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Forget what I said about Emeril. Rachael Ray i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Former private eye-turned-security guard ditch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Mann photographs the Alberta Rocky Mountains i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Simply put: the movie is boring. Cliché upon c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Now being a fan of sci fi, the trailer for thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>In 'Hoot' Logan Lerman plays Roy Eberhardt, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>This is the worst film I have ever seen.I was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>I think that Toy Soldiers is an excellent movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>I think Micheal Ironsides acting career must b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>This was a disgrace to the game FarCry i had m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review\n",
       "0          0  Forget what I said about Emeril. Rachael Ray i...\n",
       "1          0  Former private eye-turned-security guard ditch...\n",
       "2          0  Mann photographs the Alberta Rocky Mountains i...\n",
       "3          0  Simply put: the movie is boring. Cliché upon c...\n",
       "4          1  Now being a fan of sci fi, the trailer for thi...\n",
       "5          1  In 'Hoot' Logan Lerman plays Roy Eberhardt, th...\n",
       "6          0  This is the worst film I have ever seen.I was ...\n",
       "7          1  I think that Toy Soldiers is an excellent movi...\n",
       "8          0  I think Micheal Ironsides acting career must b...\n",
       "9          0  This was a disgrace to the game FarCry i had m..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_data()\n",
    "data.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These include sentiment scores for each review, but we will not make use of this for now."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "We will need to split sentences into words and and map words into numbers that our models can work with - i.e., we need to perform tokenization. We have developed a bespoke tokenizer class for this dataset - `IMDBtokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TEXT: Forget what I said about Emeril. Rachael Ray is ...\n",
      "TOKENS FROM TEXT: 822, 49, 11, 299, 43, 38969, 3, 10411, 1391, 8 ...\n",
      "TEXT FROM TOKENS: forget what i said about emeril. rachael ray is ...\n"
     ]
    }
   ],
   "source": [
    "reviews = data[\"review\"].tolist()\n",
    "review = reviews[0]\n",
    "\n",
    "tokenizer = IMDBTokenizer(reviews)\n",
    "tokenized_review = tokenizer(review)\n",
    "tokenised_review_decoded = tokenizer.tokens2text(tokenized_review[:10])\n",
    "\n",
    "print(f\"ORIGINAL TEXT: {review[:47]} ...\")\n",
    "print(f\"TOKENS FROM TEXT: {', '.join(str(t) for t in tokenized_review[:10])} ...\")\n",
    "print(f\"TEXT FROM TOKENS: {tokenised_review_decoded} ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have also provided an implementation of the tokenizer used in the GPT models that is based on [Byte Pair Encoding](https://huggingface.co/learn/nlp-course/chapter6/5?fw=pt). This approach to tokenisation can be thought of as a midway between character-level and word-level encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "ORIGINAL TEXT: Forget what I said about Emeril. Rachael Ray is ...\n",
      "TOKENS FROM TEXT: 19574, 440, 209, 1242, 391, 23177, 223, 14, 21282, 3444 ...\n",
      "TEXT FROM TOKENS: Forget what I said about Emeril. Rachael Ray ...\n"
     ]
    }
   ],
   "source": [
    "gpt_tokenizer = GPTTokenizer(reviews)\n",
    "tokenized_review = gpt_tokenizer(reviews[0])\n",
    "tokenized_review[:10]\n",
    "tokenised_review_decoded = gpt_tokenizer.tokens2text(tokenized_review[:10])\n",
    "\n",
    "print(f\"ORIGINAL TEXT: {review[:47]} ...\")\n",
    "print(f\"TOKENS FROM TEXT: {', '.join(str(t) for t in tokenized_review[:10])} ...\")\n",
    "print(f\"TEXT FROM TOKENS: {tokenised_review_decoded} ...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Datasets\n",
    "\n",
    "PyTorch provides a simple framework for making it easier to assemble batches of data when training models with algorithms like [stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent).\n",
    "\n",
    "The first part of this framework involves implementing the `Dataset` class interface that enables downstream objects to interact with data in a consistent way (via the pre-defined interface).\n",
    "\n",
    "We have implemented a custom `Dataset` class called `FilmReviewSequence` that will enable indexed access to token sequences that can be used for training generative language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[:5]: tensor([822,  49,  11, 299,  43])\n",
      "y[:5]: tensor([   49,    11,   299,    43, 38969])\n"
     ]
    }
   ],
   "source": [
    "tokenized_reviews = [tokenizer(review) for review in reviews]\n",
    "dataset = FilmReviewSequences(tokenized_reviews)\n",
    "x, y = dataset[0]\n",
    "\n",
    "print(f\"x[:5]: {x[:5]}\")\n",
    "print(f\"y[:5]: {y[:5]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `y` here is the same sequence held in `x`, but shifted forwards by one position, as the task is to predict the next token(s) in the sequence, given an initial sequence of tokens (or 'prompt').\n",
    "\n",
    "For convenience, `make_sequence_datasets` is provided that will yield datasets for training, validation and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training data = 42709 reviews\n",
      "size of validation data = 2209 reviews\n",
      "size of test data = 4959 reviews\n",
      "\n",
      "vocabulary size = 74421 tokens\n"
     ]
    }
   ],
   "source": [
    "datasets = make_sequence_datasets()\n",
    "\n",
    "print(f\"size of training data = {len(datasets.train_data)} reviews\")\n",
    "print(f\"size of validation data = {len(datasets.val_data)} reviews\")\n",
    "print(f\"size of test data = {len(datasets.test_data)} reviews\")\n",
    "\n",
    "print(f\"\\nvocabulary size = {datasets.tokenizer.vocab_size} tokens\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch DataLoaders\n",
    "\n",
    "The second component of PyTorch's data handling framework is the `DataLoader` class. This class takes a `Dataset` and yields batches of data to be used in each iteration of a model's training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=10, collate_fn=pad_seq2seq_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because each movie review has a different length and all data from a single batch has to have the same shape, we pad sequences to the same length using our `pad_seq2seq_data` function, called automatically by the data loader when yielding a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batches = [batch for batch in data_loader]\n",
    "x_batch, y_batch = data_batches[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily verify that the batches have the expected properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 40])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 40])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
